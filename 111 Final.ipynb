{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Generation Using Markov Chains and Scikit\n",
    "## Introduction\n",
    "\n",
    "After some time thinking of an idea for a final project, I came up with an idea to create a bot that someone could talk to that would reply as if it were a character from a movie or television show. For my own enjoyment, I chose Michael Scott from The Office. My idea was to take the input a speaker spoke to the bot (That's right! With a little twist of speech recognition.), find the lines which were most similar in the show, from any character, and generate a response based on Michael's response to these lines. This more or less worked. For more details on the process and my successes and fails, see below.\n",
    "\n",
    "\n",
    "I did have some inspiration from students at Stanford University who created similar bot but using Neural Machine Translation, their project is linked [here](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/custom/15709728.pdf)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Professor Barnwell helped me locate my [data](https://docs.google.com/spreadsheets/d/18wS5AAwOh8QO95RwHLS95POmSNKA2jjzdt0phrxeAE0/edit#gid=747974534), which was a document on Google Sheets which contained every line in the scripts in The Office attached to the name of the character it belonged to as well as season and episode. Here is my data set in the form of a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>line_text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[on the phone] Yes, I'd like to speak to your ...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I've, uh, I've been at Dunder Mifflin for 12 y...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Well. I don't know.</td>\n",
       "      <td>Pam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>If you think she's cute now, you should have s...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>What?</td>\n",
       "      <td>Pam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  season  episode  scene  \\\n",
       "0   1       1        1      1   \n",
       "1   2       1        1      1   \n",
       "2   3       1        1      1   \n",
       "3   4       1        1      1   \n",
       "4   5       1        1      1   \n",
       "5   6       1        1      2   \n",
       "6   7       1        1      3   \n",
       "7   8       1        1      3   \n",
       "8   9       1        1      3   \n",
       "9  10       1        1      3   \n",
       "\n",
       "                                           line_text  speaker  deleted  \n",
       "0  All right Jim. Your quarterlies look very good...  Michael    False  \n",
       "1         Oh, I told you. I couldn't close it. So...      Jim    False  \n",
       "2  So you've come to the master for guidance? Is ...  Michael    False  \n",
       "3         Actually, you called me in here, but yeah.      Jim    False  \n",
       "4    All right. Well, let me show you how it's done.  Michael    False  \n",
       "5  [on the phone] Yes, I'd like to speak to your ...  Michael    False  \n",
       "6  I've, uh, I've been at Dunder Mifflin for 12 y...  Michael    False  \n",
       "7                                Well. I don't know.      Pam    False  \n",
       "8  If you think she's cute now, you should have s...  Michael    False  \n",
       "9                                              What?      Pam    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"the-office-lines - scripts.csv\")\n",
    "data = data.loc[data['deleted'] == False]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the line_text portion of the data frame, I decided I needed to clean up the text a bit more so my Markov generator to work better in the future. To do this I created new column in which all of the text in line_text was converted to lower case and all brackets and the text inside of the brackets were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>line_text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>deleted</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "      <td>all right jim. your quarterlies look very good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "      <td>oh, i told you. i couldn't close it. so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "      <td>so you've come to the master for guidance? is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "      <td>actually, you called me in here, but yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "      <td>all right. well, let me show you how it's done.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[on the phone] Yes, I'd like to speak to your ...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "      <td>yes, i'd like to speak to your office manager...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I've, uh, I've been at Dunder Mifflin for 12 y...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "      <td>i've, uh, i've been at dunder mifflin for 12 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Well. I don't know.</td>\n",
       "      <td>Pam</td>\n",
       "      <td>False</td>\n",
       "      <td>well. i don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>If you think she's cute now, you should have s...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "      <td>if you think she's cute now, you should have s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>What?</td>\n",
       "      <td>Pam</td>\n",
       "      <td>False</td>\n",
       "      <td>what?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  season  episode  scene  \\\n",
       "0   1       1        1      1   \n",
       "1   2       1        1      1   \n",
       "2   3       1        1      1   \n",
       "3   4       1        1      1   \n",
       "4   5       1        1      1   \n",
       "5   6       1        1      2   \n",
       "6   7       1        1      3   \n",
       "7   8       1        1      3   \n",
       "8   9       1        1      3   \n",
       "9  10       1        1      3   \n",
       "\n",
       "                                           line_text  speaker  deleted  \\\n",
       "0  All right Jim. Your quarterlies look very good...  Michael    False   \n",
       "1         Oh, I told you. I couldn't close it. So...      Jim    False   \n",
       "2  So you've come to the master for guidance? Is ...  Michael    False   \n",
       "3         Actually, you called me in here, but yeah.      Jim    False   \n",
       "4    All right. Well, let me show you how it's done.  Michael    False   \n",
       "5  [on the phone] Yes, I'd like to speak to your ...  Michael    False   \n",
       "6  I've, uh, I've been at Dunder Mifflin for 12 y...  Michael    False   \n",
       "7                                Well. I don't know.      Pam    False   \n",
       "8  If you think she's cute now, you should have s...  Michael    False   \n",
       "9                                              What?      Pam    False   \n",
       "\n",
       "                                               clean  \n",
       "0  all right jim. your quarterlies look very good...  \n",
       "1         oh, i told you. i couldn't close it. so...  \n",
       "2  so you've come to the master for guidance? is ...  \n",
       "3         actually, you called me in here, but yeah.  \n",
       "4    all right. well, let me show you how it's done.  \n",
       "5   yes, i'd like to speak to your office manager...  \n",
       "6  i've, uh, i've been at dunder mifflin for 12 y...  \n",
       "7                                well. i don't know.  \n",
       "8  if you think she's cute now, you should have s...  \n",
       "9                                              what?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleantext(text):\n",
    "    words = text.split()\n",
    "    words = [word.lower() for word in words]\n",
    "    words = ' '.join([str(elem) for elem in words])\n",
    "    return words\n",
    "\n",
    "def cleanertext(text):\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    for i in text:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0:\n",
    "            ret += i\n",
    "    return ret\n",
    "\n",
    "data['clean'] = data.line_text.apply(cleantext).apply(cleanertext)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "So with my original idea, having the text generate off Michael's responses was key to having the bot make logical conversation with the user. Unfortunately, I had a bit of trouble writing this function... It worked, but not as well or as consistently as I had hoped. I believe the problem has to do with the index of my data. I will show you my method here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.decomposition\n",
    "import sklearn.neighbors\n",
    "\n",
    "vect = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.8, max_features=2000, sublinear_tf=True)\n",
    "vect.fit(data.clean)\n",
    "features = vect.transform(data.clean)\n",
    "svd = sklearn.decomposition.TruncatedSVD(n_components=2)\n",
    "svd.fit(features)\n",
    "nn = sklearn.neighbors.NearestNeighbors(metric='cosine')\n",
    "nn.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>line_text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>deleted</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17502</td>\n",
       "      <td>17503</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>Question: Has anyone recently offended a Gypsy?</td>\n",
       "      <td>Dwight</td>\n",
       "      <td>False</td>\n",
       "      <td>question: has anyone recently offended a gypsy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8633</td>\n",
       "      <td>8634</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>Then I refuse.</td>\n",
       "      <td>Dwight</td>\n",
       "      <td>False</td>\n",
       "      <td>then i refuse.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  season  episode  scene  \\\n",
       "17502  17503       4        1     85   \n",
       "8633    8634       2       20     30   \n",
       "\n",
       "                                             line_text speaker  deleted  \\\n",
       "17502  Question: Has anyone recently offended a Gypsy?  Dwight    False   \n",
       "8633                                    Then I refuse.  Dwight    False   \n",
       "\n",
       "                                                 clean  \n",
       "17502  question: has anyone recently offended a gypsy?  \n",
       "8633                                    then i refuse.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def findlinesx(query):\n",
    "    query_features = vect.transform([query])\n",
    "    dists, ixs = nn.kneighbors(query_features, n_neighbors=25)\n",
    "    matches = data.iloc[ixs[0, 1:]].copy().id\n",
    "    for match in matches:\n",
    "        list = [matches.index]\n",
    "    for match in list:\n",
    "        replies = data.iloc[match + 1]\n",
    "    for match in replies:\n",
    "        return replies.loc[replies.speaker == \"Dwight\"]\n",
    "                   \n",
    "findlinesx(\"what day is today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it did work... But not with the consistency or results that I wanted. So I decided to scratch that part and go back to just finding the most similar lines, which worked much better! For this method I needed to make a data frame which included just Michael's lines, then create a vectorizer and fit it to that data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael = data.loc[data.speaker==\"Michael\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "\n",
    "vect = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.8, max_features=2000, sublinear_tf=True)\n",
    "vect.fit(michael.clean)\n",
    "features = vect.transform(michael.clean)\n",
    "svd = sklearn.decomposition.TruncatedSVD(n_components=2)\n",
    "svd.fit(features)\n",
    "nn = sklearn.neighbors.NearestNeighbors(metric='cosine')\n",
    "nn.fit(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I created a couple different functions. The first was a function to find ngrams I will use in my Markov generator later. The second was a function to find thirty lines similar to a given input. And the third was to choose a random start word to generate the Markov Chain with. The third function improved my project tremendously in terms of generating a natural output. Without it you would have to choose a word you would like Michael to reply with, and with that the response is less organic and the options for the text to follow are extremely limited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "\n",
    "def find_ngrams(text, sizeOfNgram):\n",
    "    bigrams = []\n",
    "    for ngram in nltk.ngrams(tokenizer.tokenize(text), sizeOfNgram):\n",
    "        tempDict = {\n",
    "            \"Size\":    sizeOfNgram - 1,\n",
    "            \"Gram\": ngram[:-1],\n",
    "            \"Word\":  ngram[-1],\n",
    "        }\n",
    "        bigrams.append(tempDict)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findthelines(query):\n",
    "    in_list = [1, 2, 3, 4]\n",
    "    new_list = []\n",
    "    query_features = vect.transform([query])\n",
    "    dists, ixs = nn.kneighbors(query_features, n_neighbors=30)\n",
    "    matches = michael.iloc[ixs[0, 1:]].copy()\n",
    "    for x in in_list:\n",
    "        new_list = new_list + matches[\"clean\"].apply(find_ngrams, sizeOfNgram=x).sum()\n",
    "    my_data = pd.DataFrame.from_records(new_list)\n",
    "    return my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startwords(text):\n",
    "    query_features = vect.transform([text])\n",
    "    dists, ixs = nn.kneighbors(query_features, n_neighbors=30)\n",
    "    matches = michael.iloc[ixs[0, 1:]].copy()\n",
    "    mtext = matches[\"clean\"].tolist()\n",
    "    mstr = ' '.join([str(elem) for elem in mtext])\n",
    "    mylist = mstr.split()  \n",
    "    bigrams = zip(mylist, mylist[1:])\n",
    "    return(random.choice([b[1] for b in bigrams if b[0].endswith('.')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I created a function which would take an input, find the most common lines, find a random startword from those lines, and then generate a Markov Chain accordingly! It works! Well, most of the time... Depending on the input it may or may not get a bit stuck on itself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's ju - they didn't have any more of those clips that is where the magic happens ! right over here , do ? do you know what that hold paper .\n"
     ]
    }
   ],
   "source": [
    "def newfunct(query):\n",
    "    mylist = [startwords(query)]\n",
    "    mydata = findthelines(query)\n",
    "    grouped_grams = mydata.groupby(['Size', 'Gram', 'Word']).size()\n",
    "    while mylist[-1] != \".\":\n",
    "        if grouped_grams.loc[1, (mylist[-1], )].sample(1, replace=True, weights=grouped_grams.loc[1, (mylist[-1], )]).index.size >= 3:\n",
    "            mylist.append(grouped_grams.loc[1, (mylist[-1], )].sample(1, weights=grouped_grams.loc[1, (mylist[-1], )]).index[0])\n",
    "        if grouped_grams.loc[1, (mylist[-1], )].sample(1, replace=True, weights=grouped_grams.loc[1, (mylist[-1], )]).index.size <= 3:\n",
    "            mylist.append(grouped_grams.loc[1, (mylist[-1], )].sample(1, weights=grouped_grams.loc[1, (mylist[-1], )]).index[0])\n",
    "    print(\" \".join(mylist))\n",
    "    \n",
    "newfunct(\"do you have any paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, I wrote some more code so my Markov generator was a bit more interactive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Michael Scott:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fad4591efde4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello, my name is Michael Scott:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_dialogue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mhuman_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mhuman_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuman_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Michael: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         )\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "continue_dialogue = True\n",
    "print(\"Hello, my name is Michael Scott:\")\n",
    "while(continue_dialogue == True):\n",
    "    human_text = input()\n",
    "    human_text = human_text.lower()\n",
    "    print(\"Michael: \", end=\"\")\n",
    "    print(newfunct(human_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like my Markov generator, it works, but not all of the time. It tends to like certain inputs better than others. I wasn't too happy with it so I decided I wanted to try to improve it. I wrote some more functions and some more code which improved the bots ability to have a conversation a lot! Take a look below! \n",
    "\n",
    "(I often need to interrupt the kernel after running the line ahead of this one in order for the next functions to run, just a tip!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtext = michael[\"clean\"].tolist()\n",
    "mstr = ' '.join([str(elem) for elem in mtext])\n",
    "msents = nltk.sent_tokenize(mstr)\n",
    "mwords = nltk.word_tokenize(mstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnlemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def perform_lemmatization(tokens):\n",
    "    return [wnlemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
    "\n",
    "def get_processed_text(document):\n",
    "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    mresponse = ''\n",
    "    msents.append(user_input)\n",
    "\n",
    "    word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words='english')\n",
    "    all_word_vectors = word_vectorizer.fit_transform(msents)\n",
    "    similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "    similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
    "\n",
    "    matched_vector = similar_vector_values.flatten()\n",
    "    matched_vector.sort()\n",
    "    vector_matched = matched_vector[-2]\n",
    "\n",
    "    if vector_matched == 0:\n",
    "        mrobo = mresponse + \"I am sorry, I could not understand you\"\n",
    "        return mresponse\n",
    "    else:\n",
    "        mresponse = mresponse + msents[similar_sentence_number]\n",
    "        return mresponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_inputs = (\"hey\", \"good morning\", \"good evening\", \"morning\", \"evening\", \"hi\", \"whatsup\")\n",
    "greeting_responses = [\"hey\", \"hey hows you?\", \"*nods*\", \"hello, how you doing\", \"hello\", \"Welcome, I am good and you\"]\n",
    "\n",
    "def generate_greeting_response(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am your friend Michael. How are you today:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " good\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what did you do today\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh, what did you do today?\n"
     ]
    }
   ],
   "source": [
    "continue_dialogue = True\n",
    "print(\"Hello, I am your friend Michael. How are you today:\")\n",
    "while(continue_dialogue == True):\n",
    "    human_text = input()\n",
    "    human_text = human_text.lower()\n",
    "    if human_text != 'bye':\n",
    "        if human_text == 'thanks' or human_text == 'thank you very much' or human_text == 'thank you':\n",
    "            continue_dialogue = False\n",
    "            print(\"Michael: Most welcome\")\n",
    "        else:\n",
    "            if generate_greeting_response(human_text) != None:\n",
    "                print(\"Michael: \" + generate_greeting_response(human_text))\n",
    "            else:\n",
    "                print(\"Michael: \", end=\"\")\n",
    "                print(generate_response(human_text))\n",
    "                msents.remove(human_text)\n",
    "    else:\n",
    "        continue_dialogue = False\n",
    "        print(\"Michael: Good bye and take care of yourself...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dialogue doesn't make the most sense, but it is a start and it works! I honestly think that if I had gotten the bit at the beginning to work, where the function responded to the input with an output that was correalated with the response, this bot would have worked much better, making conversation that actually flowed. This, like you can see, more or less repeats the question or statement you say to it. But, despite that bit, I am pretty happy with it for now!\n",
    "\n",
    "My next object to tackle was speech recognition. This proved to be the easiest portion of my project, and it makes it pretty fun to use! I chose to use Houndify as my oustide platform. \n",
    "\n",
    "(Once again, you often have to interrupt the kernel after the last bit of code for this to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "houndify_client_id = \"nUNnnQI4iNwkx37FwrzRRw==\"\n",
    "houndify_client_key = \"pSqDYq1cKrL5IIvv6UmXtfE3d5bLWdUggz_qDMPxo2btetPORPzcI5nYGZm7Vy0oAIbH6q_dbThA6ShcpWDYEA==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try speaking here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mic as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source, phrase_time_limit=8)\n",
    "\n",
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the speech recognition is all set up, we can attach it to a function. I chose to attach it to newfunct. Go ahead and try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newfunct_audio(audio):\n",
    "    text = r.recognize_houndify(audio, houndify_client_id, houndify_client_key)\n",
    "    print(\"You said:\", text)\n",
    "    return newfunct(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said: how are you doing today\n",
      "what are you doing , how we doing ? need anything ? need anything ? you doing ? need anything ? what are you doing , ernie , what are you ? you ? what are you doing ? need anything ? you doing ? you doing ? you doing ? you doing ? need anything ? you already there ? you doing , jan .\n"
     ]
    }
   ],
   "source": [
    "with mic as source:\n",
    "    audio = r.listen(source, phrase_time_limit=5)\n",
    "\n",
    "newfunct_audio(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Overall, I am pretty happy with how my project turned out. It definitely has room for improvement, and you might catch me during this quarantine trying to redo the portion with the replies so it doesn't haunt me forever. In the future I could explore using spacy in this more to make more coherent text, but this kind of works without it. It's inline with how Michael speaks anyways. \n",
    "\n",
    "I would really like to explore this again but with neural machine translation, and then compare that to Markov chains. Maybe I could make something more applicable to the real world. But, this was fun for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
